{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2 — Bayesian Change-Point Modeling (PyMC)\n",
                "\n",
                "Notebook content saved as **task2_bayesian_changepoint.ipynb.json** for download.\n",
                "Rename locally to **task2_bayesian_changepoint.ipynb**.\n",
                "\n",
                "## Sections\n",
                "1. Import + repo path setup (`sys.path`)\n",
                "2. Load processed log returns + feature checks\n",
                "3. EDA plots via repo utilities\n",
                "4. Model 1 (mandatory): mean switch\n",
                "5. Model 2 (extension): sigma switch\n",
                "6. Diagnostics + posterior plots\n",
                "7. Posterior predictive checks (PPC)\n",
                "8. Impact summaries + tau sample → date mapping + tau-date mass plots\n",
                "9. Events near change-point (optional)\n",
                "10. Optional model comparison (LOO)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1) Import setup (repo-aware) + plotting defaults"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import annotations\n",
                "\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.font_manager as fm\n",
                "import arviz as az\n",
                "import pymc as pm\n",
                "\n",
                "# --- Default Font\n",
                "\n",
                "plt.rcParams['font.family'] = 'sans-serif'  # use system default\n",
                "plt.rcParams['axes.unicode_minus'] = False  # fixes minus sign display\n",
                "\n",
                "# --- Make repo root importable ---\n",
                "_HERE = Path.cwd()\n",
                "if (_HERE / 'src').exists():\n",
                "    _ROOT = _HERE\n",
                "elif (_HERE.parent / 'src').exists():\n",
                "    _ROOT = _HERE.parent\n",
                "else:\n",
                "    _ROOT = _HERE\n",
                "    for p in _HERE.parents:\n",
                "        if (p / 'src').exists():\n",
                "            _ROOT = p\n",
                "            break\n",
                "\n",
                "if str(_ROOT) not in sys.path:\n",
                "    sys.path.insert(0, str(_ROOT))\n",
                "\n",
                "print('Repo root:', _ROOT)\n",
                "az.style.use('arviz-darkgrid')\n",
                "plt.rcParams['figure.dpi'] = 120"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2) Import project modules (exact repo imports)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.config import (\n",
                "    ensure_dirs,\n",
                "    DATA_PROCESSED_DIR,\n",
                "    DATA_RAW_DIR,\n",
                "    REPORTS_FIGURES_DIR,\n",
                "    REPORTS_INTERIM_DIR,\n",
                "    LOG_RETURNS_FILENAME,\n",
                "    EVENTS_FILENAME,\n",
                "    ROLLING_VOL_WINDOW_DAYS,\n",
                "    EVENT_MATCH_WINDOW_DAYS,\n",
                "    COL_DATE,\n",
                "    COL_LOG_RETURN,\n",
                ")\n",
                "\n",
                "from src.data.io_task2 import load_log_returns_csv, ensure_log_features\n",
                "from src.events.io_task2 import load_events\n",
                "from src.eda.plots_task2 import plot_price, plot_log_returns, plot_rolling_volatility\n",
                "\n",
                "from src.models.bayes_changepoint_task2 import (\n",
                "    build_switchpoint_mean_model,\n",
                "    build_switchpoint_sigma_model,\n",
                "    sample_model,\n",
                "    compute_impact_summary,\n",
                "    compute_sigma_impact_summary,\n",
                "    map_tau_samples_to_dates,\n",
                "    compute_convergence_report,\n",
                "    prior_settings_summary,\n",
                "    standardize,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3) Create output directories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ensure_dirs()\n",
                "REPORTS_FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
                "REPORTS_INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
                "print('Figures dir:', REPORTS_FIGURES_DIR)\n",
                "print('Interim dir:', REPORTS_INTERIM_DIR)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4) Load processed log returns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = DATA_PROCESSED_DIR / LOG_RETURNS_FILENAME\n",
                "df = load_log_returns_csv(data_path)\n",
                "df = ensure_log_features(df)\n",
                "df[[COL_DATE, COL_LOG_RETURN]].head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5) EDA figures (via repo plotting utilities)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Price series\n",
                "fig1 = plot_price(df)\n",
                "fig1.savefig(REPORTS_FIGURES_DIR / 'nb_task2_01_price_raw.png', dpi=150, bbox_inches='tight')\n",
                "plt.close(fig1)\n",
                "\n",
                "# Log returns\n",
                "fig2 = plot_log_returns(df)\n",
                "fig2.savefig(REPORTS_FIGURES_DIR / 'nb_task2_02_log_returns.png', dpi=150, bbox_inches='tight')\n",
                "plt.close(fig2)\n",
                "\n",
                "# Rolling volatility\n",
                "fig3 = plot_rolling_volatility(df, window=ROLLING_VOL_WINDOW_DAYS)\n",
                "fig3.savefig(REPORTS_FIGURES_DIR / f'nb_task2_03_rolling_vol_{ROLLING_VOL_WINDOW_DAYS}d.png', dpi=150, bbox_inches='tight')\n",
                "plt.close(fig3)\n",
                "\n",
                "print('Saved EDA figures to', REPORTS_FIGURES_DIR)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6) Prepare model inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y = df[COL_LOG_RETURN].to_numpy(dtype=float)\n",
                "mask = np.isfinite(y)\n",
                "y_clean = y[mask]\n",
                "dates_clean = df.loc[mask, COL_DATE].reset_index(drop=True)\n",
                "\n",
                "print('n_clean:', len(y_clean))\n",
                "print('date range:', dates_clean.iloc[0], '→', dates_clean.iloc[-1])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7) (Optional) Standardize returns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "STANDARDIZE_RETURNS = False\n",
                "\n",
                "y_model = y_clean\n",
                "y_mean = None\n",
                "y_std = None\n",
                "if STANDARDIZE_RETURNS:\n",
                "    y_model, y_mean, y_std = standardize(y_clean)\n",
                "    print('Standardized returns with mean/std:', y_mean, y_std)\n",
                "else:\n",
                "    print('Using raw returns scale.')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8) Fit Model 1 (mandatory): mean switch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_m = build_switchpoint_mean_model(y_model)\n",
                "idata_m = sample_model(\n",
                "    model_m,\n",
                "    draws=2000,\n",
                "    tune=2000,\n",
                "    chains=4,\n",
                "    target_accept=0.9,\n",
                "    random_seed=42,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8.1 Model 1 diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary_m = az.summary(idata_m, var_names=['tau','mu_1','mu_2','sigma'], round_to=6)\n",
                "summary_m\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "conv_m = compute_convergence_report(idata_m, ['tau','mu_1','mu_2','sigma'])\n",
                "conv_m\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "az.plot_trace(idata_m, var_names=['tau','mu_1','mu_2','sigma']);\n",
                "plt.tight_layout();\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m1_trace.png', dpi=150, bbox_inches='tight');\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "az.plot_posterior(idata_m, var_names=['tau']);\n",
                "plt.tight_layout();\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m1_tau_posterior.png', dpi=150, bbox_inches='tight');\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9) Fit Model 2 (extension): sigma switch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_s = build_switchpoint_sigma_model(y_model)\n",
                "idata_s = sample_model(\n",
                "    model_s,\n",
                "    draws=2000,\n",
                "    tune=2000,\n",
                "    chains=4,\n",
                "    target_accept=0.9,\n",
                "    random_seed=42,\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9.1 Model 2 diagnostics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary_s = az.summary(idata_s, var_names=['tau','mu','sigma_1','sigma_2'], round_to=6)\n",
                "summary_s\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "conv_s = compute_convergence_report(idata_s, ['tau','mu','sigma_1','sigma_2'])\n",
                "conv_s\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "az.plot_trace(idata_s, var_names=['tau','mu','sigma_1','sigma_2']);\n",
                "plt.tight_layout();\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m2_trace.png', dpi=150, bbox_inches='tight');\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "az.plot_posterior(idata_s, var_names=['tau']);\n",
                "plt.tight_layout();\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m2_tau_posterior.png', dpi=150, bbox_inches='tight');\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "az.plot_posterior(idata_s, var_names=['sigma_1','sigma_2']);\n",
                "plt.tight_layout();\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m2_sigma_posterior.png', dpi=150, bbox_inches='tight');\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10) Posterior predictive checks (PPC)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with model_m:\n",
                "    ppc_m = pm.sample_posterior_predictive(idata_m, random_seed=42)\n",
                "idata_m.extend(ppc_m)\n",
                "az.plot_ppc(idata_m, data_pairs={'obs':'obs'}, num_pp_samples=200);\n",
                "plt.tight_layout();\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m1_ppc.png', dpi=150, bbox_inches='tight');\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with model_s:\n",
                "    ppc_s = pm.sample_posterior_predictive(idata_s, random_seed=42)\n",
                "idata_s.extend(ppc_s)\n",
                "az.plot_ppc(idata_s, data_pairs={'obs':'obs'}, num_pp_samples=200);\n",
                "plt.tight_layout();\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m2_ppc.png', dpi=150, bbox_inches='tight');\n",
                "plt.show();\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11) Impact summaries + tau sample mapping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "impact_mean = compute_impact_summary(idata_m, dates_clean)\n",
                "impact_sigma = compute_sigma_impact_summary(idata_s, dates_clean)\n",
                "impact_mean, impact_sigma\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pd.DataFrame([impact_mean.__dict__]).to_csv(REPORTS_INTERIM_DIR / 'nb_task2_m1_impact_summary.csv', index=False)\n",
                "pd.DataFrame([impact_sigma]).to_csv(REPORTS_INTERIM_DIR / 'nb_task2_m2_sigma_impact_summary.csv', index=False)\n",
                "print('Saved impact summaries to', REPORTS_INTERIM_DIR)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tau_m_df = map_tau_samples_to_dates(idata_m, dates_clean)\n",
                "tau_s_df = map_tau_samples_to_dates(idata_s, dates_clean)\n",
                "tau_m_df.to_csv(REPORTS_INTERIM_DIR / 'nb_task2_m1_tau_samples.csv', index=False)\n",
                "tau_s_df.to_csv(REPORTS_INTERIM_DIR / 'nb_task2_m2_tau_samples.csv', index=False)\n",
                "tau_m_df.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 11.1 Tau-date posterior mass plots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
                "ax.hist(pd.to_datetime(tau_m_df['tau_date']), bins=60)\n",
                "ax.set_title('Posterior mass of change-point date (Model 1: mean switch)')\n",
                "ax.set_xlabel('date')\n",
                "plt.tight_layout()\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m1_tau_date_mass.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
                "ax.hist(pd.to_datetime(tau_s_df['tau_date']), bins=60)\n",
                "ax.set_title('Posterior mass of change-point date (Model 2: sigma switch)')\n",
                "ax.set_xlabel('date')\n",
                "plt.tight_layout()\n",
                "plt.savefig(REPORTS_FIGURES_DIR / 'nb_task2_m2_tau_date_mass.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12) Optional model comparison (LOO)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    cmp = az.compare({'mean_switch': idata_m, 'sigma_switch': idata_s}, ic='loo')\n",
                "    cmp.to_csv(REPORTS_INTERIM_DIR / 'nb_task2_model_comparison_loo.csv')\n",
                "    cmp\n",
                "except Exception as e:\n",
                "    print('LOO comparison failed:', e)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13) Optional: events near inferred change point (±window)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "events_path = DATA_RAW_DIR / EVENTS_FILENAME\n",
                "if events_path.exists():\n",
                "    ev = load_events(events_path)\n",
                "\n",
                "    # Model 1\n",
                "    cp_mean = pd.to_datetime(impact_mean.tau_mode_date)\n",
                "    ev_mean = ev.copy()\n",
                "    ev_mean['days_from_cp'] = (ev_mean[COL_DATE] - cp_mean).dt.days\n",
                "    ev_mean_near = ev_mean.loc[ev_mean['days_from_cp'].abs() <= EVENT_MATCH_WINDOW_DAYS].copy()\n",
                "    ev_mean_near.to_csv(REPORTS_INTERIM_DIR / 'nb_task2_events_near_cp_mean_switch.csv', index=False)\n",
                "\n",
                "    # Model 2\n",
                "    cp_sigma = pd.to_datetime(impact_sigma['tau_mode_date'])\n",
                "    ev_sigma = ev.copy()\n",
                "    ev_sigma['days_from_cp'] = (ev_sigma[COL_DATE] - cp_sigma).dt.days\n",
                "    ev_sigma_near = ev_sigma.loc[ev_sigma['days_from_cp'].abs() <= EVENT_MATCH_WINDOW_DAYS].copy()\n",
                "    ev_sigma_near.to_csv(REPORTS_INTERIM_DIR / 'nb_task2_events_near_cp_sigma_switch.csv', index=False)\n",
                "\n",
                "    print('Saved events-near-CP tables to', REPORTS_INTERIM_DIR)\n",
                "    ev_mean_near.head()\n",
                "else:\n",
                "    print('No events file found; skipping.')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14) Save run metadata"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "meta = {\n",
                "    'standardize_returns': STANDARDIZE_RETURNS,\n",
                "    'y_mean_if_standardized': y_mean,\n",
                "    'y_std_if_standardized': y_std,\n",
                "    'priors_used': dict(prior_settings_summary(y_model, mu_prior_sigma=None, sigma_prior_sigma=None)),\n",
                "    'm1_convergence': getattr(conv_m, '__dict__', str(conv_m)),\n",
                "    'm2_convergence': getattr(conv_s, '__dict__', str(conv_s)),\n",
                "    'm1_cp_date_mode': impact_mean.tau_mode_date,\n",
                "    'm2_cp_date_mode': impact_sigma.get('tau_mode_date', None),\n",
                "}\n",
                "(REPORTS_INTERIM_DIR / 'nb_task2_run_metadata.json').write_text(json.dumps(meta, indent=2))\n",
                "print('Saved:', REPORTS_INTERIM_DIR / 'nb_task2_run_metadata.json')\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
